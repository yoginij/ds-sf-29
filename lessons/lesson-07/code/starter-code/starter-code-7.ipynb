{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class 7- Starter code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Create sample data and fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x': range(100), 'y': range(100)})\n",
    "biased_df  = df.copy()\n",
    "biased_df.loc[:20, 'x'] = 1\n",
    "biased_df.loc[:20, 'y'] = 1\n",
    "\n",
    "def append_jitter(series):\n",
    "    jitter = np.random.random_sample(size=100)\n",
    "    return series + jitter\n",
    "\n",
    "df['x'] = append_jitter(df.x)\n",
    "df['y'] = append_jitter(df.y)\n",
    "\n",
    "biased_df['x'] = append_jitter(biased_df.x)\n",
    "biased_df['y'] = append_jitter(biased_df.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.158628490169\n"
     ]
    }
   ],
   "source": [
    "## fit\n",
    "lm = linear_model.LinearRegression().fit(df[['x']], df['y'])\n",
    "print metrics.mean_squared_error(df['y'], lm.predict(df[['x']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.164518804399\n"
     ]
    }
   ],
   "source": [
    "## biased fit\n",
    "lm = linear_model.LinearRegression().fit(biased_df[['x']], biased_df['y'])\n",
    "print metrics.mean_squared_error(df['y'], lm.predict(df[['x']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "#### Intro to cross validation with bike share data from last time. We will be modeling casual ridership. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "wd = '../../assets/dataset/'\n",
    "bikeshare = pd.read_csv(wd + 'bikeshare.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Create dummy variables and set outcome (dependent) variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>weather_1</th>\n",
       "      <th>weather_2</th>\n",
       "      <th>weather_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.42</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17349</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17350</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17351</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17352</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17353</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17354</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17355</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17356</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17357</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17358</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17359</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17360</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17361</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17362</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17363</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17364</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17365</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17366</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17367</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17368</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17369</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17370</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17371</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17372</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17373</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17379 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       temp   hum  weather_1  weather_2  weather_3\n",
       "0      0.24  0.81        1.0        0.0        0.0\n",
       "1      0.22  0.80        1.0        0.0        0.0\n",
       "2      0.22  0.80        1.0        0.0        0.0\n",
       "3      0.24  0.75        1.0        0.0        0.0\n",
       "4      0.24  0.75        1.0        0.0        0.0\n",
       "5      0.24  0.75        0.0        1.0        0.0\n",
       "6      0.22  0.80        1.0        0.0        0.0\n",
       "7      0.20  0.86        1.0        0.0        0.0\n",
       "8      0.24  0.75        1.0        0.0        0.0\n",
       "9      0.32  0.76        1.0        0.0        0.0\n",
       "10     0.38  0.76        1.0        0.0        0.0\n",
       "11     0.36  0.81        1.0        0.0        0.0\n",
       "12     0.42  0.77        1.0        0.0        0.0\n",
       "13     0.46  0.72        0.0        1.0        0.0\n",
       "14     0.46  0.72        0.0        1.0        0.0\n",
       "15     0.44  0.77        0.0        1.0        0.0\n",
       "16     0.42  0.82        0.0        1.0        0.0\n",
       "17     0.44  0.82        0.0        1.0        0.0\n",
       "18     0.42  0.88        0.0        0.0        1.0\n",
       "19     0.42  0.88        0.0        0.0        1.0\n",
       "20     0.40  0.87        0.0        1.0        0.0\n",
       "21     0.40  0.87        0.0        1.0        0.0\n",
       "22     0.40  0.94        0.0        1.0        0.0\n",
       "23     0.46  0.88        0.0        1.0        0.0\n",
       "24     0.46  0.88        0.0        1.0        0.0\n",
       "25     0.44  0.94        0.0        1.0        0.0\n",
       "26     0.42  1.00        0.0        1.0        0.0\n",
       "27     0.46  0.94        0.0        1.0        0.0\n",
       "28     0.46  0.94        0.0        1.0        0.0\n",
       "29     0.42  0.77        0.0        0.0        1.0\n",
       "...     ...   ...        ...        ...        ...\n",
       "17349  0.24  0.44        0.0        1.0        0.0\n",
       "17350  0.34  0.61        1.0        0.0        0.0\n",
       "17351  0.22  0.47        1.0        0.0        0.0\n",
       "17352  0.20  0.51        1.0        0.0        0.0\n",
       "17353  0.20  0.55        1.0        0.0        0.0\n",
       "17354  0.20  0.51        1.0        0.0        0.0\n",
       "17355  0.18  0.55        1.0        0.0        0.0\n",
       "17356  0.18  0.55        1.0        0.0        0.0\n",
       "17357  0.16  0.59        1.0        0.0        0.0\n",
       "17358  0.16  0.59        1.0        0.0        0.0\n",
       "17359  0.14  0.69        1.0        0.0        0.0\n",
       "17360  0.16  0.64        1.0        0.0        0.0\n",
       "17361  0.16  0.64        1.0        0.0        0.0\n",
       "17362  0.16  0.64        1.0        0.0        0.0\n",
       "17363  0.14  0.69        1.0        0.0        0.0\n",
       "17364  0.18  0.64        0.0        1.0        0.0\n",
       "17365  0.20  0.69        0.0        1.0        0.0\n",
       "17366  0.22  0.60        0.0        1.0        0.0\n",
       "17367  0.24  0.56        0.0        1.0        0.0\n",
       "17368  0.26  0.44        0.0        1.0        0.0\n",
       "17369  0.28  0.45        0.0        1.0        0.0\n",
       "17370  0.28  0.45        0.0        1.0        0.0\n",
       "17371  0.26  0.48        0.0        1.0        0.0\n",
       "17372  0.26  0.48        0.0        1.0        0.0\n",
       "17373  0.26  0.48        0.0        1.0        0.0\n",
       "17374  0.26  0.60        0.0        1.0        0.0\n",
       "17375  0.26  0.60        0.0        1.0        0.0\n",
       "17376  0.26  0.60        1.0        0.0        0.0\n",
       "17377  0.26  0.56        1.0        0.0        0.0\n",
       "17378  0.26  0.65        1.0        0.0        0.0\n",
       "\n",
       "[17379 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.get_dummies(bikeshare.weathersit, prefix='weather')\n",
    "modeldata = bikeshare[['temp', 'hum']].join(weather[['weather_1', 'weather_2', 'weather_3']])\n",
    "y = bikeshare.casual \n",
    "modeldata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a cross valiation with 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = cross_validation.KFold(len(modeldata), n_folds=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ CROSS VALIDATION each fold ~~~~\n",
      "Model 1\n",
      "MSE: 1764.96737943\n",
      "R2: 0.311898068528\n",
      "Model 2\n",
      "MSE: 1750.30356839\n",
      "R2: 0.311806727\n",
      "Model 3\n",
      "MSE: 1666.11372643\n",
      "R2: 0.311931837671\n",
      "Model 4\n",
      "MSE: 1528.9177514\n",
      "R2: 0.311885896347\n",
      "Model 5\n",
      "MSE: 1657.84916178\n",
      "R2: 0.311910807462\n",
      "~~~~ SUMMARY OF CROSS VALIDATION ~~~~\n",
      "Mean of MSE for all folds: 1673.63031749\n",
      "Mean of R2 for all folds: 0.311886667402\n"
     ]
    }
   ],
   "source": [
    "mse_values = []\n",
    "scores = []\n",
    "n= 0\n",
    "print \"~~~~ CROSS VALIDATION each fold ~~~~\"\n",
    "for train_index, test_index in kf:\n",
    "    lm = linear_model.LinearRegression().fit(modeldata.iloc[train_index], y.iloc[train_index])\n",
    "    mse_values.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(modeldata.iloc[test_index])))\n",
    "    scores.append(lm.score(modeldata, y))\n",
    "    n+=1\n",
    "    print 'Model', n\n",
    "    print 'MSE:', mse_values[n-1]\n",
    "    print 'R2:', scores[n-1]\n",
    "\n",
    "\n",
    "print \"~~~~ SUMMARY OF CROSS VALIDATION ~~~~\"\n",
    "print 'Mean of MSE for all folds:', np.mean(mse_values)\n",
    "print 'Mean of R2 for all folds:', np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ Single Model ~~~~\n",
      "MSE of single model: 1672.58110765\n",
      "R2:  0.311934605989\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.LinearRegression().fit(modeldata, y)\n",
    "print \"~~~~ Single Model ~~~~\"\n",
    "print 'MSE of single model:', metrics.mean_squared_error(y, lm.predict(modeldata))\n",
    "print 'R2: ', lm.score(modeldata, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check\n",
    "While the cross validated approach here generated more overall error, which of the two approaches would predict new data more accurately: the single model or the cross validated, averaged one? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are ways to improve our model with regularization. \n",
    "Let's check out the effects on MSE and R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~ OLS ~~~\n",
      "OLS MSE:  1672.58110765\n",
      "OLS R2: 0.311934605989\n",
      "~~~ Lasso ~~~\n",
      "Lasso MSE:  1725.41581608\n",
      "Lasso R2: 0.290199495922\n",
      "~~~ Ridge ~~~\n",
      "Ridge MSE:  1672.60490113\n",
      "Ridge R2: 0.311924817843\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.LinearRegression().fit(modeldata, y)\n",
    "print \"~~~ OLS ~~~\"\n",
    "print 'OLS MSE: ', metrics.mean_squared_error(y, lm.predict(modeldata))\n",
    "print 'OLS R2:', lm.score(modeldata, y)\n",
    "\n",
    "lm = linear_model.Lasso().fit(modeldata, y)\n",
    "print \"~~~ Lasso ~~~\"\n",
    "print 'Lasso MSE: ', metrics.mean_squared_error(y, lm.predict(modeldata))\n",
    "print 'Lasso R2:', lm.score(modeldata, y)\n",
    "\n",
    "lm = linear_model.Ridge().fit(modeldata, y)\n",
    "print \"~~~ Ridge ~~~\"\n",
    "print 'Ridge MSE: ', metrics.mean_squared_error(y, lm.predict(modeldata))\n",
    "print 'Ridge R2:', lm.score(modeldata, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figuring out the alphas can be done by \"hand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1e-10\n",
      "[ 112.68901765  -84.01121684  -24.68489063  -21.00314493  -21.71893628]\n",
      "1672.58110765\n",
      "Alpha: 1e-09\n",
      "[ 112.68901765  -84.01121684  -24.68489061  -21.00314491  -21.71893626]\n",
      "1672.58110765\n",
      "Alpha: 1e-08\n",
      "[ 112.68901765  -84.01121684  -24.6848904   -21.00314471  -21.71893606]\n",
      "1672.58110765\n",
      "Alpha: 1e-07\n",
      "[ 112.68901763  -84.01121682  -24.68488837  -21.00314268  -21.71893403]\n",
      "1672.58110765\n",
      "Alpha: 1e-06\n",
      "[ 112.68901745  -84.01121667  -24.68486804  -21.00312237  -21.71891373]\n",
      "1672.58110765\n",
      "Alpha: 1e-05\n",
      "[ 112.68901562  -84.01121509  -24.68466472  -21.00291929  -21.71871079]\n",
      "1672.58110765\n",
      "Alpha: 0.0001\n",
      "[ 112.68899732  -84.01119938  -24.68263174  -21.00088873  -21.71668162]\n",
      "1672.58110765\n",
      "Alpha: 0.001\n",
      "[ 112.68881437  -84.01104228  -24.66232204  -20.98060316  -21.69640993]\n",
      "1672.58110774\n",
      "Alpha: 0.01\n",
      "[ 112.68698753  -84.00947323  -24.46121539  -20.77973778  -21.49568404]\n",
      "1672.58111645\n",
      "Alpha: 0.1\n",
      "[ 112.66896732  -83.99396383  -22.63109556  -18.95202277  -19.66942371]\n",
      "1672.58185208\n",
      "Alpha: 1.0\n",
      "[ 112.50129738  -83.84805622  -13.38214934   -9.72671278  -10.46162477]\n",
      "1672.60490113\n",
      "Alpha: 10.0\n",
      "[ 110.96062533  -82.49604961   -3.94431741   -0.51765034   -1.45024412]\n",
      "1672.83347262\n",
      "Alpha: 100.0\n",
      "[ 97.69060562 -71.17602377  -0.31585194   1.18284675  -1.33281591]\n",
      "1686.31830362\n",
      "Alpha: 1000.0\n",
      "[ 44.59923075 -30.85843772   5.07876321   0.05369643  -5.107457  ]\n",
      "1937.81576044\n",
      "Alpha: 10000.0\n",
      "[ 7.03007064 -5.07733082  3.29039029 -1.2136063  -2.06842808]\n",
      "2314.83675678\n",
      "Alpha: 100000.0\n",
      "[ 0.75195708 -0.56490872  0.52067881 -0.25075496 -0.26895254]\n",
      "2415.77806566\n",
      "Alpha: 1000000.0\n",
      "[ 0.07576571 -0.05727511  0.05520142 -0.0273591  -0.02774349]\n",
      "2429.28026459\n",
      "Alpha: 10000000.0\n",
      "[ 0.00758239 -0.00573569  0.0055535  -0.00276043 -0.00278317]\n",
      "2430.68891798\n",
      "Alpha: 100000000.0\n",
      "[ 0.0007583  -0.00057365  0.00055569 -0.00027629 -0.00027841]\n",
      "2430.83041212\n",
      "Alpha: 1000000000.0\n",
      "[  7.58303020e-05  -5.73659720e-05   5.55719458e-05  -2.76314619e-05\n",
      "  -2.78414555e-05]\n",
      "2430.84456787\n",
      "Alpha: 10000000000.0\n",
      "[  7.58303603e-06  -5.73660542e-06   5.55722818e-06  -2.76317091e-06\n",
      "  -2.78415441e-06]\n",
      "2430.84598351\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-10, 10, 21)\n",
    "for a in alphas:\n",
    "    print 'Alpha:', a\n",
    "    lm = linear_model.Ridge(alpha=a)\n",
    "    lm.fit(modeldata, y)\n",
    "    print lm.coef_\n",
    "    print metrics.mean_squared_error(y, lm.predict(modeldata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or we can use grid search to make this faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'RandimizedSearchCV'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-3b8fd7abdffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m gs2 = grid_search.RandimizedSearchCV(\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mElasticNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mparam_distrubtions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'l1_ratio'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'selection'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'random'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'random_state'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'RandimizedSearchCV'"
     ]
    }
   ],
   "source": [
    "from sklearn import grid_search\n",
    "\n",
    "alphas = np.logspace(-10, 10, 21)\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=linear_model.Ridge(),\n",
    "    param_grid={'alpha': alphas},\n",
    "    scoring='mean_squared_error')\n",
    "\n",
    "gs.fit(modeldata, y)\n",
    "\n",
    "gs1 = grid_search.GridSearchCV(\n",
    "    estimator=linear_model.ElasticNet(),\n",
    "    param_grid={'alpha': alphas,'l1_ratio':[0.5,0.6,0.7]},\n",
    "    scoring='mean_squared_error')\n",
    "\n",
    "gs2 = grid_search.RandimizedSearchCV(\n",
    "    estimator=linear_model.ElasticNet(),\n",
    "    param_distrubtions={'alpha': scipy.stats.distribution.uniform,'l1_ratio':[0.5,0.6,0.7],'selection':['random'],'random_state':r},\n",
    "    scoring='mean_squared_error')\n",
    "\n",
    "gs3 = grid_search.RandomizedSearchCV(\n",
    "   estimator=linear_model.ElasticNet(),\n",
    "   param_distributions={'alpha': scipy.stats.distributions.uniform(),\n",
    "              'l1_ratio': scipy.stats.distributions.uniform()},\n",
    "   scoring='mean_squared_error')\n",
    "\n",
    "gs3.fit(modeldata, y)\n",
    "\n",
    "print gs1\n",
    "print gs2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:466: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': array([  1.00000e-10,   1.00000e-09,   1.00000e-08,   1.00000e-07,\n",
       "         1.00000e-06,   1.00000e-05,   1.00000e-04,   1.00000e-03,\n",
       "         1.00000e-02,   1.00000e-01,   1.00000e+00,   1.00000e+01,\n",
       "         1.00000e+02,   1.00000e+03,   1.00000e+04,   1.00000e+05,\n",
       "         1.00000e+06,   1.00000e+07,   1.00000e+08,   1.00000e+09,\n",
       "         1.00000e+10]), 'l1_ratio': [0.5, 0.6, 0.7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='mean_squared_error',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.fit(modeldata, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1814.09369133\n"
     ]
    }
   ],
   "source": [
    "print gs.best_score_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mean squared error here comes in negative, so let's make it positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1814.09369133\n"
     ]
    }
   ],
   "source": [
    "print -gs.best_score_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### explains which grid_search setup worked best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=0.01, copy_X=True, fit_intercept=True, l1_ratio=0.6,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print gs1.best_estimator_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### shows all the grid pairings and their performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: -1817.60095, std: 542.18184, params: {'alpha': 1e-10, 'l1_ratio': 0.5}, mean: -1817.60095, std: 542.18184, params: {'alpha': 1e-10, 'l1_ratio': 0.6}, mean: -1817.60095, std: 542.18184, params: {'alpha': 1e-10, 'l1_ratio': 0.7}, mean: -1817.60095, std: 542.18184, params: {'alpha': 1.0000000000000001e-09, 'l1_ratio': 0.5}, mean: -1817.60095, std: 542.18184, params: {'alpha': 1.0000000000000001e-09, 'l1_ratio': 0.6}, mean: -1817.60095, std: 542.18184, params: {'alpha': 1.0000000000000001e-09, 'l1_ratio': 0.7}, mean: -1817.60093, std: 542.18192, params: {'alpha': 1e-08, 'l1_ratio': 0.5}, mean: -1817.60093, std: 542.18190, params: {'alpha': 1e-08, 'l1_ratio': 0.6}, mean: -1817.60094, std: 542.18189, params: {'alpha': 1e-08, 'l1_ratio': 0.7}, mean: -1817.60072, std: 542.18269, params: {'alpha': 9.9999999999999995e-08, 'l1_ratio': 0.5}, mean: -1817.60077, std: 542.18253, params: {'alpha': 9.9999999999999995e-08, 'l1_ratio': 0.6}, mean: -1817.60082, std: 542.18236, params: {'alpha': 9.9999999999999995e-08, 'l1_ratio': 0.7}, mean: -1817.59867, std: 542.19043, params: {'alpha': 9.9999999999999995e-07, 'l1_ratio': 0.5}, mean: -1817.59913, std: 542.18875, params: {'alpha': 9.9999999999999995e-07, 'l1_ratio': 0.6}, mean: -1817.59960, std: 542.18707, params: {'alpha': 9.9999999999999995e-07, 'l1_ratio': 0.7}, mean: -1817.57813, std: 542.26774, params: {'alpha': 1.0000000000000001e-05, 'l1_ratio': 0.5}, mean: -1817.58275, std: 542.25096, params: {'alpha': 1.0000000000000001e-05, 'l1_ratio': 0.6}, mean: -1817.58738, std: 542.23417, params: {'alpha': 1.0000000000000001e-05, 'l1_ratio': 0.7}, mean: -1817.37354, std: 543.03836, params: {'alpha': 0.0001, 'l1_ratio': 0.5}, mean: -1817.41950, std: 542.87130, params: {'alpha': 0.0001, 'l1_ratio': 0.6}, mean: -1817.46556, std: 542.70408, params: {'alpha': 0.0001, 'l1_ratio': 0.7}, mean: -1815.43262, std: 550.58991, params: {'alpha': 0.001, 'l1_ratio': 0.5}, mean: -1815.83840, std: 548.97262, params: {'alpha': 0.001, 'l1_ratio': 0.6}, mean: -1816.26003, std: 547.34462, params: {'alpha': 0.001, 'l1_ratio': 0.7}, mean: -1810.46487, std: 614.87277, params: {'alpha': 0.01, 'l1_ratio': 0.5}, mean: -1809.75157, std: 602.48354, params: {'alpha': 0.01, 'l1_ratio': 0.6}, mean: -1809.93264, std: 589.29225, params: {'alpha': 0.01, 'l1_ratio': 0.7}, mean: -2016.98416, std: 832.41394, params: {'alpha': 0.10000000000000001, 'l1_ratio': 0.5}, mean: -1975.75897, std: 812.62924, params: {'alpha': 0.10000000000000001, 'l1_ratio': 0.6}, mean: -1928.84844, std: 785.04078, params: {'alpha': 0.10000000000000001, 'l1_ratio': 0.7}, mean: -2429.56748, std: 949.50184, params: {'alpha': 1.0, 'l1_ratio': 0.5}, mean: -2412.29395, std: 947.60692, params: {'alpha': 1.0, 'l1_ratio': 0.6}, mean: -2385.69256, std: 944.35985, params: {'alpha': 1.0, 'l1_ratio': 0.7}, mean: -2542.43347, std: 964.11452, params: {'alpha': 10.0, 'l1_ratio': 0.5}, mean: -2542.43347, std: 964.11452, params: {'alpha': 10.0, 'l1_ratio': 0.6}, mean: -2542.43347, std: 964.11452, params: {'alpha': 10.0, 'l1_ratio': 0.7}, mean: -2542.43347, std: 964.11452, params: {'alpha': 100.0, 'l1_ratio': 0.5}, mean: -2542.43347, std: 964.11452, params: {'alpha': 100.0, 'l1_ratio': 0.6}, mean: -2542.43347, std: 964.11452, params: {'alpha': 100.0, 'l1_ratio': 0.7}, mean: -2542.43347, std: 964.11452, params: {'alpha': 1000.0, 'l1_ratio': 0.5}, mean: -2542.43347, std: 964.11452, params: {'alpha': 1000.0, 'l1_ratio': 0.6}, mean: -2542.43347, std: 964.11452, params: {'alpha': 1000.0, 'l1_ratio': 0.7}, mean: -2542.43347, std: 964.11452, params: {'alpha': 10000.0, 'l1_ratio': 0.5}, mean: -2542.43347, std: 964.11452, params: {'alpha': 10000.0, 'l1_ratio': 0.6}, mean: -2542.43347, std: 964.11452, params: {'alpha': 10000.0, 'l1_ratio': 0.7}, mean: -2542.43347, std: 964.11452, params: {'alpha': 100000.0, 'l1_ratio': 0.5}, mean: -2542.43347, std: 964.11452, params: {'alpha': 100000.0, 'l1_ratio': 0.6}, mean: -2542.43347, std: 964.11452, params: {'alpha': 100000.0, 'l1_ratio': 0.7}, mean: -2542.43347, std: 964.11452, params: {'alpha': 1000000.0, 'l1_ratio': 0.5}, mean: -2542.43347, std: 964.11452, params: {'alpha': 1000000.0, 'l1_ratio': 0.6}, mean: -2542.43347, std: 964.11452, params: {'alpha': 1000000.0, 'l1_ratio': 0.7}, mean: -2542.43347, std: 964.11452, params: {'alpha': 10000000.0, 'l1_ratio': 0.5}, mean: -2542.43347, std: 964.11452, params: {'alpha': 10000000.0, 'l1_ratio': 0.6}, mean: -2542.43347, std: 964.11452, params: {'alpha': 10000000.0, 'l1_ratio': 0.7}, mean: -2542.43347, std: 964.11452, params: {'alpha': 100000000.0, 'l1_ratio': 0.5}, mean: -2542.43347, std: 964.11452, params: {'alpha': 100000000.0, 'l1_ratio': 0.6}, mean: -2542.43347, std: 964.11452, params: {'alpha': 100000000.0, 'l1_ratio': 0.7}, mean: -2542.43347, std: 964.11452, params: {'alpha': 1000000000.0, 'l1_ratio': 0.5}, mean: -2542.43347, std: 964.11452, params: {'alpha': 1000000000.0, 'l1_ratio': 0.6}, mean: -2542.43347, std: 964.11452, params: {'alpha': 1000000000.0, 'l1_ratio': 0.7}, mean: -2542.43347, std: 964.11452, params: {'alpha': 10000000000.0, 'l1_ratio': 0.5}, mean: -2542.43347, std: 964.11452, params: {'alpha': 10000000000.0, 'l1_ratio': 0.6}, mean: -2542.43347, std: 964.11452, params: {'alpha': 10000000000.0, 'l1_ratio': 0.7}]\n"
     ]
    }
   ],
   "source": [
    "print gs1.grid_scores_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2 is better than 6.2\n",
      "found better solution! using 5.2\n",
      "4.2 is better than 5.2\n",
      "found better solution! using 4.2\n",
      "3.2 is better than 4.2\n",
      "found better solution! using 3.2\n",
      "2.2 is better than 3.2\n",
      "found better solution! using 2.2\n",
      "1.2 is better than 2.2\n",
      "found better solution! using 1.2\n",
      "0.2 is better than 1.2\n",
      "found better solution! using 0.2\n",
      "6.0 is closest to 6.2\n"
     ]
    }
   ],
   "source": [
    "num_to_approach, start, steps, optimized = 6.2, 0., [-1, 1], False\n",
    "while not optimized:\n",
    "    current_distance = num_to_approach - start\n",
    "    got_better = False\n",
    "    next_steps = [start + i for i in steps]\n",
    "    for n in next_steps:\n",
    "        distance = np.abs(num_to_approach - n)\n",
    "        if distance < current_distance:\n",
    "            got_better = True\n",
    "            print distance, 'is better than', current_distance\n",
    "            current_distance = distance\n",
    "            start = n\n",
    "    if got_better:\n",
    "        print 'found better solution! using', current_distance\n",
    "        a += 1\n",
    "    else:\n",
    "        optimized = True\n",
    "        print start, 'is closest to', num_to_approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Bonus: \n",
    "implement a stopping point, similar to what n_iter would do in gradient descent when we've reached \"good enough\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Demo: Application of Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent R2: 0.30853517891\n",
      "Gradient Descent MSE: 1680.84459185\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.SGDRegressor()\n",
    "lm.fit(modeldata, y)\n",
    "print \"Gradient Descent R2:\", lm.score(modeldata, y)\n",
    "print \"Gradient Descent MSE:\", metrics.mean_squared_error(y, lm.predict(modeldata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Check: Untuned, how well did gradient descent perform compared to OLS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Independent Practice: Bike data revisited\n",
    "\n",
    "There are tons of ways to approach a regression problem. The regularization techniques appended to ordinary least squares optimizes the size of coefficients to best account for error. Gradient Descent also introduces learning rate (how aggressively do we solve the problem), epsilon (at what point do we say the error margin is acceptable), and iterations (when should we stop no matter what?)\n",
    "\n",
    "For this deliverable, our goals are to:\n",
    "\n",
    "- implement the gradient descent approach to our bike-share modeling problem,\n",
    "- show how gradient descent solves and optimizes the solution,\n",
    "- demonstrate the grid_search module!\n",
    "\n",
    "While exploring the Gradient Descent regressor object, you'll build a grid search using the stochastic gradient descent estimator for the bike-share data set. Continue with either the model you evaluated last class or the simpler one from today. In particular, be sure to implement the \"param_grid\" in the grid search to get answers for the following questions:\n",
    "\n",
    "- With a set of alpha values between 10^-10 and 10^-1, how does the mean squared error change?\n",
    "- Based on the data, we know when to properly use l1 vs l2 regularization. By using a grid search with l1_ratios between 0 and 1 (increasing every 0.05), does that statement hold true? If not, did gradient descent have enough iterations?\n",
    "- How do these results change when you alter the learning rate (eta0)?\n",
    "\n",
    "**Bonus**: Can you see the advantages and disadvantages of using gradient descent after finishing this exercise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starter Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {} # put your gradient descent parameters here\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=linear_model.SGDRegressor(),\n",
    "    cv=cross_validation.KFold(len(modeldata), n_folds=5, shuffle=True),\n",
    "    param_grid=params,\n",
    "    scoring='mean_squared_error',\n",
    "    )\n",
    "\n",
    "gs.fit(modeldata, y)\n",
    "\n",
    "print 'BEST ESTIMATOR'\n",
    "print -gs.best_score_\n",
    "print gs.best_estimator_\n",
    "print 'ALL ESTIMATORS'\n",
    "print gs.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## go for it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
